{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yclin/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yclin/Workspace/cleverhans/cleverhans/loss.py:62: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-08-26 03:52:58,900 cleverhans] Epoch 0 took 2.34281849861145 seconds\n",
      "[INFO 2018-08-26 03:52:59,054 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9874\n",
      "Test accuracy on adversarial examples: 0.5961\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yclin/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples using FGSM\n",
    "and train a model using adversarial training with TensorFlow.\n",
    "It is very similar to mnist_tutorial_keras_tf.py, which does the same\n",
    "thing but with a dependence on keras.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1412.6572\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.python.platform import flags\n",
    "import logging\n",
    "\n",
    "from cleverhans.loss import LossCrossEntropy\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import train, model_eval\n",
    "from cleverhans.attacks import SpatialTransformationMethod\n",
    "from cleverhans.utils import AccuracyReport, set_log_level\n",
    "from cleverhans_tutorials.tutorial_models import ModelBasicCNN\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def mnist_tutorial(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=6, batch_size=128,\n",
    "                   learning_rate=0.001,\n",
    "                   clean_train=True,\n",
    "                   testing=False,\n",
    "                   backprop_through_attack=False,\n",
    "                   nb_filters=64, num_threads=None,\n",
    "                   label_smoothing=True):\n",
    "    \"\"\"\n",
    "    MNIST cleverhans tutorial\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param clean_train: perform normal training on clean examples only\n",
    "                        before performing adversarial training.\n",
    "    :param testing: if true, complete an AccuracyReport for unit tests\n",
    "                    to verify that performance is adequate\n",
    "    :param backprop_through_attack: If True, backprop through adversarial\n",
    "                                    example construction process during\n",
    "                                    adversarial training.\n",
    "    :param clean_train: if true, train on clean examples\n",
    "    :return: an AccuracyReport object\n",
    "    \"\"\"\n",
    "\n",
    "    # Object used to keep track of (and return) key accuracies\n",
    "    report = AccuracyReport()\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Set logging level to see debug information\n",
    "    set_log_level(logging.INFO)\n",
    "\n",
    "    # Create TF session\n",
    "    if num_threads:\n",
    "        config_args = dict(intra_op_parallelism_threads=1)\n",
    "    else:\n",
    "        config_args = {}\n",
    "    sess = tf.Session(config=tf.ConfigProto(**config_args))\n",
    "\n",
    "    # Get MNIST test data\n",
    "    x_train, y_train, x_test, y_test = data_mnist(train_start=train_start,\n",
    "                                                  train_end=train_end,\n",
    "                                                  test_start=test_start,\n",
    "                                                  test_end=test_end)\n",
    "    # Use Image Parameters\n",
    "    img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "    nb_classes = y_train.shape[1]\n",
    "\n",
    "    if label_smoothing:\n",
    "        label_smooth = .1\n",
    "        y_train = y_train.clip(label_smooth /\n",
    "                               (nb_classes-1), 1. - label_smooth)\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n",
    "                                          nchannels))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    eval_params = {'batch_size': 128}\n",
    "    stm_params = {\n",
    "        'batch_size': 128,\n",
    "        'n_samples': 10,\n",
    "        'dx_min': -0.1,\n",
    "        'dx_max': 0.1,\n",
    "        'n_dxs': 3,\n",
    "        'dy_min': -0.1,\n",
    "        'dy_max': 0.1,\n",
    "        'n_dys': 3,\n",
    "        'angle_min': -30,\n",
    "        'angle_max': 30,\n",
    "        'n_angles': 11\n",
    "    }\n",
    "\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "    sess = tf.Session()\n",
    "\n",
    "    def do_eval(preds, x_set, y_set, report_key, is_adv=None):\n",
    "        acc = model_eval(sess, x, y, preds, x_set, y_set, args=eval_params)\n",
    "        setattr(report, report_key, acc)\n",
    "        if is_adv is None:\n",
    "            report_text = None\n",
    "        elif is_adv:\n",
    "            report_text = 'adversarial'\n",
    "        else:\n",
    "            report_text = 'legitimate'\n",
    "        if report_text:\n",
    "            print('Test accuracy on %s examples: %0.4f' % (report_text, acc))\n",
    "\n",
    "    if clean_train:\n",
    "        model = ModelBasicCNN('model1', nb_classes, nb_filters)\n",
    "        preds = model.get_logits(x)\n",
    "        loss = LossCrossEntropy(model, smoothing=0.1)\n",
    "\n",
    "        def evaluate():\n",
    "            do_eval(preds, x_test, y_test, 'clean_train_clean_eval', False)\n",
    "\n",
    "        train(sess, loss, x, y, x_train, y_train, evaluate=evaluate,\n",
    "              args=train_params, rng=rng, var_list=model.get_params())\n",
    "\n",
    "        # Calculate testing error\n",
    "        do_eval(preds, x_test, y_test, 'train_clean_test_clean_eval')\n",
    "\n",
    "        # Calculate training error\n",
    "        if testing:\n",
    "            do_eval(preds, x_train, y_train, 'train_clean_train_clean_eval')\n",
    "        \n",
    "        stm = SpatialTransformationMethod(model, sess=sess)\n",
    "        adv_x = stm.generate(x, **stm_params)\n",
    "        preds_adv = model.get_logits(adv_x)\n",
    "\n",
    "        # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "        do_eval(preds_adv, x_test, y_test, 'clean_train_adv_eval', True)\n",
    "\n",
    "        # Calculate training error\n",
    "        if testing:\n",
    "            do_eval(preds_adv, x_train, y_train, 'train_clean_train_adv_eval')\n",
    "\n",
    "    return report\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist_tutorial(nb_epochs=FLAGS.nb_epochs, batch_size=FLAGS.batch_size,\n",
    "                   learning_rate=FLAGS.learning_rate,\n",
    "                   clean_train=FLAGS.clean_train,\n",
    "                   backprop_through_attack=FLAGS.backprop_through_attack,\n",
    "                   nb_filters=FLAGS.nb_filters)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_integer('nb_filters', 64, 'Model size multiplier')\n",
    "    flags.DEFINE_integer('nb_epochs', 1, 'Number of epochs to train model')\n",
    "    flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "    flags.DEFINE_float('learning_rate', 0.001, 'Learning rate for training')\n",
    "    flags.DEFINE_bool('clean_train', True, 'Train on clean examples')\n",
    "    flags.DEFINE_bool('backprop_through_attack', False,\n",
    "                      ('If True, backprop through adversarial example '\n",
    "                       'construction process during adversarial training'))\n",
    "\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
